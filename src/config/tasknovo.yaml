
identificador: TC01
proposito: >
    Este plano de teste descreve o escopo, os recursos, a abordagem e o cronograma
    das atividades de teste relacionadas ao arquivo tasks.yaml. O objetivo é garantir
    que cada tarefa definida no arquivo tenha aderência aos padrões esperados de automação de testes e BDD.

introducao: >
    O arquivo tasks.yaml define várias tarefas automatizadas de geração e revisão de código,
    incluindo transformações de casos de uso em Gherkin, criação e revisão de testes xUnit.net,
    além de tarefas de gerenciamento e debate entre versões de código geradas.
    Este plano garante que essas tarefas gerem saídas coerentes, corretas e dentro dos padrões técnicos esperados.

itens:
    gherkin_code
    gherkin_review
    manager_gherkin_task
    xunit_code_proposal
    xunit_review
    debate
    manager_debate_xunit_task
    manager_xunit_task

funcionalidades:
descricao: >
    Conversão de casos de uso em arquivos Gherkin com cenários de sucesso e erro.
    Revisão e aprimoramento de Gherkin gerado.
    Consolidação de múltiplas versões de código Gherkin.
    Geração de código de teste xUnit.net conforme padrões de projeto.
    Revisão e consolidação de múltiplas versões de testes xUnit.
    Avaliação e debate entre versões de código com justificativas.
nao_testadas: >
    Integrações externas (ex: CI/CD ou pipelines de deploy) não estão cobertas por este plano.

abordagem: >
    Serão usadas ferramentas como Test.AI e Pytest, além de leitores de .yaml.
    Cada tarefa será testada quanto à entrada, substituição de placeholders e formatação esperada.

criterios_aceite: >
    O texto gerado deve respeitar o campo expected_output.
    Nenhuma tag markdown (``` ou similar) deve estar presente.

suspensao_retornada: >
    Os testes serão suspensos caso o .yaml esteja corrompido ou mal formatado,
    ou caso alguma dependência crítica falhe. Ao retomar, será refeita a validação
    e reexecução dos testes interrompidos.

produtos:
    Plano de Teste (tasknovo.yaml)
    Arquivos python de teste (test.py)

tarefas_de_teste:
    Validar todas as chaves principais (description, expected_output, output_example).
    Executar o parser .yaml e detectar placeholders não resolvidos.
    Testar o formato da saída de cada tarefa.
    Consolidar resultados em relatório final.

ambiente:
    sistema_operacional: "Linux/Windows compatível com Python 3.10+"
    ferramentas: ".yaml parser, Pytest, Test.AI" 
    dependencias: "Nenhuma integração externa — execução local determinística."

treinamento: >
    Estrutura e sintaxe de arquivos .yaml
    Padrões IEEE 829-1998
    Testes BDD (Gherkin) e xUnit.net
    Boas práticas de automação e revisão de testes

cronograma:  "1. Análise do .yaml 2. Criação dos testes 3. Execução dos testes 4. Revisão e Relatório Final"

riscos: ".yaml mal formatado, Validação automática antes do teste, Reexecução com backup do arquivo"

gherkin_code:
    description: |
        Transform the following use case into BDD files with outline scenarios for success and error cases.
        For each attribute, generate a custom error message when it is not provided.
        Focus on generalizing the scenarios and covering more possibilities with examples.
              
        {user_case}
        Example output format:
        Scenario Outline: Successfully add a modality
                Given the server provides the modality data <sigla>, <name>, <description>, <percentage>, <start_date>, <scholarships>
                And the server selects the resolution <resolution>
                When the system validates and saves the modality
                Then the system should save the modality with the status "In editing"
                
            Examples:
                | sigla | name | description | percentage | start_date | scholarships | resolution |
                | ABC   | Name | Desc       | 10         | 2024-01-01 | Scholarship1 | Res1       |

            Scenario Outline: Add modality with error
                Given the server provides the modality data <sigla>, <name>, <description>, <percentage>, <start_date>, <scholarships>
                And the server selects the resolution <resolution>
                When the system validates and cannot save the modality
                Then the system should return an error message "<error_message>"
                
            Examples:
                | sigla | name | description | percentage | start_date | scholarships | resolution | error_message                     |
                | ABC   | Name | Desc       | -10        | 2024-01-01 | Scholarship1 | Res1      | Percentage cannot be negative     |
    expected_output: "ONLY the gherkin code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"

gherkin_review:
    description: |
        Based on the user case below, review and adjust the generated Gherkin code if necessary. Pay attention to writing inconsistencies and syntax errors. Verify that the scenarios cover all possibilities. Focus on generalizing the scenarios to cover more possibilities with examples.
        {user_case}
    expected_output: "ONLY the gherkin code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"

manager_gherkin_task:
    description: "Read and compare all generated Gherkin codes and develop a final version based on them."
    expected_output: "ONLY the gherkin code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"

xunit_code_proposal:
    description: |
        {feature}

        Based on the feature described, write xUnit.net test code that adheres to the following guidelines:
        using ConectaFapes.Application.DTOs.CadastroModalidadesBolsas.Request;
        using ConectaFapes.Application.DTOs.CadastroModalidadesBolsas.Response;
        using ConectaFapes.Test.Shared;
        using System.Net;
        using System.Text;
        using System.Text.Json;

        the path for the feature file should be: [FeatureFile("../../../Features/<feature title in pascal case>Feature.feature")]

        Consistency with HttpClient and WebApplicationFactory: Ensure consistent use of HttpClient and WebApplicationFactory throughout the test implementation.

        Validations: Implement validations to ensure:
        Request and response class names include the DTO suffix.
        Strings must not be null or empty; validate them before making any API call.
        Clear error messages are displayed in case of type mismatches or missing attributes.

        Annotations: Use Given, When, and Then annotations for test steps with explicit parameter binding.

        Examples for Operations: Include robust examples for GET, POST, PUT, DELETE, and specific operations like activate and deactivate.
        Restrictions: Do not use Theory, InlineData, or Fact. All tests should focus on scenario-based behavior with clear steps.
    output_example: xunit_code_output
    expected_output: "ONLY the C# code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG. Also the justifications for what was generated."

xunit_review:
    description: |
        Based on the feature below and the given code, review and adjust the xUnit.net test code if necessary. Pay close attention to coding inconsistencies, syntax errors, and adherence to best practices. Verify that the tests cover all scenarios described in the feature and that edge cases are accounted for. Focus on making the tests efficient and readable, and ensure that they follow xUnit.net standards.
        {feature}
    output_example: xunit_code_output
    expected_output: "ONLY the xUnit.net test code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"

debate:
    description: |
        Based on the feature, xUnit code, and given feedback, discuss and return feedback on possible improvements and approaches to the problem, along with a new code proposal.
        NOTE: Use Given, When, Then annotations with parameter binding. DO NOT use Theory, InlineData, or Fact.
        {feature}
    output_example: xunit_code_output
    expected_output: "ONLY the C# code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG. The feedback on the previous proposal and the new proposal with justifications for this"

manager_debate_xunit_task:
    description: |
        {feature}
        Based on the feature above, review the generated xUnit.net code and develop an improved final version based on it.
        NOTE: Use Given, When, Then annotations with parameter binding. DO NOT use Theory, InlineData, or Fact.
    output_example: xunit_code_output
    expected_output: "ONLY the C# code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"

manager_xunit_task:
    description: |
        code 1:
        {}


        code 2:
        {}

        code 3:
        {}

        Read and compare all generated C# xUnit codes and develop a final version based on them.
    expected_output: "ONLY the C# xUnit code generated without the code block like ```, DO NOT USE ANY MARKDOWN TAG"
    output_example: xunit_code_output

aprovacoes: "Membros de Gestão de projeto"

responsabilidades:
    papel: "Designer de tasks"
    responsabilidade: "Definir casos de teste para cada tarefa .yaml"